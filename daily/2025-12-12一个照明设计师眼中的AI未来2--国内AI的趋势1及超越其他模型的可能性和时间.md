---
title: 2025-12-12一个照明设计师眼中的AI未来2--国内AI的趋势1及超越其他模型的可能性和时间
tags: 新建,模板,小书匠
category: /小书匠/日记/2025-12
grammar_cjkRuby: true
---

#AI未来 #中国AI #现状和未来
国内AI趋势：国家层面的资源通过行政手段进行“精准滴灌”，同时通过市场准入机制倒逼国产芯片生态成熟，最终形成“高端突破、中低端国产化、市场寡头化”的格局。
以下是详细预测：
算力架构的“二元分化”：NVIDIA训练，华为推理
这是最直接的硬件趋势。
训练端（攻坚战）： 为了保持模型智商（IQ）不掉队，头部厂商（阿里、字节、DeepSeek等）会不惜一切代价获取NVIDIA算力。
渠道： 一部分通过工信部“白名单”获取合规的H200/B20等特供版；另一部分为了追求极致性能（如DeepSeek传闻中的Blackwell），会继续依赖复杂的地下走私网络（“手提箱运输”）。
目的： 确保基座模型的Scaling Law能继续由最先进的硬件驱动。
推理端（阵地战）： 大规模的应用落地、企业私有化部署将被强制或半强制地推向国产算力（华为昇腾、寒武纪等）。
逻辑： 推理对单卡算力要求不如训练严苛，且需求量巨大。通过政策（如“传统企业本地部署优先买华为”），国家正在为国产芯片创造一个巨大的强制性市场，用市场规模换取国产芯片软件栈（如CANN）的迭代成熟。
行业格局的“寡头固化”与“伪军出清”
你提到的工信部新规本质上是一次供给侧改革。
头部效应加剧： 只有拥有极强技术自证能力（如DeepSeek能做出V3）或极强资金背景（BAT）的企业，才能拿到高端算力的“入场券”。这意味着算力资源将向阿里、腾讯、字节、DeepSeek及“六小虎”中的佼佼者高度集中。
腰部与投机者退场： 那些“妄图招一堆PhD搭架子谎称自己能炼丹”的二道贩子和PPT公司，将因拿不到算力而被断粮。行业将加速洗牌，只有具备真实造血能力或真实技术壁垒的团队能活下来。
NeoCloud（新算力云）的崛起： 像某些合规的GPU云服务商将成为关键节点，他们持有H200牌照，为第二梯队提供算力租赁，成为连接硬件与应用的枢纽。
应用落地模式的转变：从“私有部署”转向“API优先”
由于传统企业被限制购买高端NVIDIA芯片用于私有化部署，未来的企业级AI应用将呈现两种路径：
路径一（API模式）： 企业如果需要最顶尖的模型能力（如GPT-4/Claude 3.5级别），只能购买头部厂商（DeepSeek、通义千问等）的API。因为只有头部厂商手里有足够的H200/Blackwell来支撑高智商模型的推理。这会极大增加头部模型厂商的营收，形成“以商养研”的良性循环。
路径二（国产一体机）： 对于数据敏感、必须本地部署的政企/金融客户，方案商将提供基于华为昇腾等国产芯片的“训推一体机”。这虽然短期内会有适配痛苦（CUDA生态壁垒），但长期将建立起独立于NVIDIA之外的中国企业级AI软件生态。
技术演进路线：极致的“软硬解耦”与“工程优化”
DeepSeek的案例（用走私的散件、可能参差不齐的硬件训练出SOTA模型）揭示了一个关键趋势：中国AI公司将逐渐点满“工程优化”的技能树。
异构计算能力： 由于算力来源复杂（可能有H100、H200、走私的Blackwell，还有国产卡），中国大模型团队必须具备极强的异构集群管理能力，在软件层面抹平硬件差异。
通信与互联优化： 走私进来的往往是单卡或拆解件，缺乏NVLink等原厂高速互联环境。DeepSeek等公司将在InfiniBand替代方案、通信压缩算法、显存优化技术（如V3中的MLA注意力机制）上投入巨大精力，力求在硬件受限的情况下榨干每一滴算力。
地缘政治下的“猫鼠游戏”常态化
DeepSeek“手提箱运芯片”的传闻如果属实，说明美国对华的高端芯片封锁存在物理上的漏洞，但也意味着获取成本极高。
未来，**“地下算力供应链”将成为行业内公开的秘密。头部公司可能会设立专门的秘密部门（或通过壳公司）在第三国进行硬件采购和拆解。同时，这种行为也会招致美国更严厉的监管（如针对实体清单的穿透式制裁），导致中国AI发展长期处于一种“带着镣铐跳舞”但依然能跳出高难度动作的状态。总结未来的中国AI界将不再是“百模大战”的混乱局面，而是进入“正规军”与“国家队”**时代：
顶层（Training）： 少数几家巨头+DeepSeek类技术极客，用特批或走私的NVIDIA顶级芯片冲刺AGI。
底层（Inference & Edge）： 广泛的行业应用和传统企业，构建在华为/寒武纪等国产算力底座上。
商业模式： 算力门槛导致中小型模型厂消亡，市场转向“巨头卖API + 方案商卖国产一体机”的双轨制。
你提到的这个现象在学术界被称为**“奖励欺骗”（Reward Hacking）或“长度偏见”（Length Bias）**。在DeepSeek R1（推理系模型）和V3的迭代中，这一问题被多次提及。
1. 相关的核心论文与评测
虽然没有一篇论文直接取名为“DeepSeek的幻觉与长度”，但以下几份关键文献和技术报告详细记录了这一现象：
Vectara Hallucination Leaderboard & Analysis (2025.02):
DeepSeek-R1 Technical Report (2025.01 - Nature/ArXiv):
2. 技术改进方案（如何修补）
要解决这个问题，DeepSeek内部（以及外部开源社区）正在尝试以下突破：
引入过程奖励模型（PRM, Process Reward Models）：
RLVR（Reinforcement Learning with Verifiable Rewards）的泛化：
二、 DeepSeek 如何追赶 Gemini 3 和 ChatGPT-5？
结合你提供的“走私芯片”背景，DeepSeek目前的处境是：用二流的硬件（拼凑的算力），通过一流的算法（MoE/MLA），试图打败拥有超一流硬件（H200/B200集群）的对手。
1. 差距在哪里？
到2025年底，DeepSeek V3/R1 与 GPT-5/Gemini 3 的核心差距不在于“做题能力”（数学/代码已持平），而在于：
多模态原生能力（Multimodal Native）： GPT-5是原生的“视听言”一体，能像人一样实时看视频流并理解。DeepSeek目前的Janus系列还是“拼接”架构（Vision Encoder + LLM），反应慢且割裂。
超长上下文的稳定性（Context Fidelity）： 虽称支持128k/1M context，但在超长文中“大海捞针”的准确率，DeepSeek仍弱于Gemini 3（Gemini的百万级token处理是其护城河）。
Agentic（智能体）能力： 即“替你做事”的能力。GPT-5已经深度集成到操作系统中操作软件，DeepSeek仍主要停留在“对话框”里。
2. 需要哪些突破？
要抹平这些差距，DeepSeek 需要在以下三个战场突围：
架构突破：彻底的稀疏化与通信优化
数据合成：System 2 数据工厂
3. 预测时间表
追赶 GPT-5 (性能对标)： 预计 6-9 个月。
完全超越： 极难。
总结未来的格局：
DeepSeek将成为**“穷人的GPT-5”或“开发者的首选”**——它足够强、极度便宜、且开源，但在处理极端复杂的企业级多模态任务时，高端市场仍会被Gemini/GPT占据。对于中国国内市场，DeepSeek就是事实上的“天花板”。