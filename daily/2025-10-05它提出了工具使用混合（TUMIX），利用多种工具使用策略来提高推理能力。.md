---
title: 2025-10-05它提出了工具使用混合（TUMIX），利用多种工具使用策略来提高推理能力。
tags: 新建,模板,小书匠
category: /小书匠/日记/2025-10
grammar_cjkRuby: true
---


Cool research paper from Google.
来自 Google 的精彩研究论文。

This is what clever context engineering looks like.
这就是巧妙的情境工程。

It proposes Tool-Use-Mixture (TUMIX), leveraging diverse tool-use strategies to improve reasoning.
它提出了工具使用混合（TUMIX），利用多种工具使用策略来提高推理能力。

This work shows how to get better reasoning from LLMs by running a bunch of diverse agents (text-only, code, search, etc.) in parallel and letting them share notes across a few rounds. Instead of brute-forcing more samples, it mixes strategies, stops when confident, and ends up both more accurate and cheaper.
这项研究展示了如何通过并行运行一系列不同的代理（纯文本、代码、搜索等）并让它们在几轮中共享笔记，从而从 LLM 中获得更佳的推理能力。它并非强制使用更多样本，而是混合使用各种策略，在有信心时停止，最终实现了更准确且更低成本的结果。

Mix different agents, not just more of one: They ran 15 different agent styles (CoT, code execution, web search, guided variants). Each agent sees both the question and other agents’ past answers, then tries again. This back-and-forth makes the group smarter than any single agent.
混合使用不同的智能体，而不是单一的智能体：他们运行了 15 种不同的智能体类型（CoT、代码执行、网页搜索、引导式变体）。每个智能体都会看到问题以及其他智能体过去的答案，然后再次尝试。这种反复的互动使得整个团队比任何单个智能体都更智能。

Stop early, save cost: More rounds don’t always help. Too much refinement can kill diversity. They use an LLM-judge to decide when to stop. That keeps accuracy high while cutting costs almost in half.
尽早结束，节省成本：更多轮次并不总是有帮助。过度细化会扼杀多样性。他们使用法学硕士评委来决定何时结束。这既能保持高准确率，又能将成本降低近一半。

Better than existing methods: Compared with other tool-augmented scaling tricks, TUMIX consistently scores higher on tough reasoning benchmarks (HLE, GPQA-Diamond, AIME). For Gemini-2.5 Pro, it pushed HLE to 34.1%, which is a notable gain.
优于现有方法：与其他工具增强的缩放技巧相比，TUMIX 在高难度推理基准测试（HLE、GPQA-Diamond、AIME）上始终得分更高。在 Gemini-2.5 Pro 上，它将 HLE 提升至 34.1%，这是一个显著的提升。

Diversity is the secret sauce: Combining text, code, and search agents beats repeatedly sampling the best single agent. More diverse tool use = more chances to land on the right reasoning path.
多样性是秘诀：将文本、代码和搜索代理结合起来，胜过反复采样最佳的单一代理。使用更多样化的工具 = 更有可能找到正确的推理路径。

Auto-agent design: They even had the LLM generate new agent types and mixed those in, which boosted results further. The sweet spot was around 12–15 different agent styles in the mix.
自动代理设计：他们甚至让法学硕士生成新的代理类型并将其混合，从而进一步提升了结果。最佳组合是混合使用大约 12 到 15 种不同的代理类型。

[https://arxiv.org/abs/2510.01279](https://t.co/eKfeV5jhrs)
