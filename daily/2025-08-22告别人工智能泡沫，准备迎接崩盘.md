---
title: 2025-08-22告别人工智能泡沫，准备迎接崩盘
tags: 新建,模板,小书匠
category: /小书匠/日记/2025-08
grammar_cjkRuby: true
---

告别人工智能泡沫，准备迎接崩盘
作者：Michael Hiltzik

对于那些没有深度参与这场人工智能狂热的人来说，可能没注意到一个重要变化：一直以来，人们觉得AI正势不可挡地变得比人还聪明，甚至会威胁人类。但这种看法，在8月7日那天，被踩了个急刹车。

那天，万众瞩目的AI公司OpenAI发布了GPT-5。这款高级产品曾被公司长期许诺，将会让所有竞争对手黯然失色，并在这项所谓的革命性技术中掀起一场新的革命。

结果呢？GPT-5彻底翻车了。事实证明，它比OpenAI自家的前辈们更难用，在很多方面能力甚至更差。它在回答用户提问时，还是会犯那些令人啼笑皆非的错误，数学能力也没什么长进（甚至更糟了），完全不是OpenAI及其首席执行官萨姆·奥特曼（Sam Altman）一直吹嘘的那种进步。

AI公司现在确实在支撑着美国经济，但这看起来非常像一个泡沫。
—— Alex Hanna，《AI的骗局》联合作者

“大家原以为这种增长会是指数级的，”技术评论家亚历克斯·汉娜（Alex Hanna）说，“但事实是，我们正在撞上一堵墙。” 汉娜与华盛顿大学的艾米丽·M·本德（Emily M. Bender）合著了一本必读新书——《AI的骗局：如何对抗科技巨头的炒作并创造我们想要的未来》（The AI Con: How to Fight Big Tech’s Hype and Create the Future We Want）。

这件事的后果，远不止是让那些曾经期待（甚至畏惧）AI渗透我们生活的商界领袖和普通民众大失所望。风险投资家和谷歌、亚马逊、微软等大公司已经在OpenAI及其众多AI实验室上投入了数千亿美元，然而，没有一家AI实验室实现了盈利。

上市公司们争先恐后地宣布自己的AI投资，或者声称自家产品拥有AI能力，希望能借此推高股价。这就像上世纪90年代，上一代企业为了在投资者眼中显得更光鲜，纷纷自称为“互联网公司”（dot-coms）一样。

英伟达（Nvidia），这家为AI研究提供强大芯片的制造商，如今在股市中的领头羊角色，几乎和90年代的另一家芯片制造商英特尔（Intel Corp.）一模一样——都在帮助支撑着整个股票牛市。

如果AI的承诺最终像当年的“互联网公司”一样，只是个海市蜃楼，那么股票投资者们可能要面临一场痛苦的清算了。

而GPT-5令人沮丧的发布，可能会让清算之日提前到来。“AI公司现在确实在支撑着美国经济，但这看起来非常像一个泡沫，”汉娜告诉我。

这次发布会是如此令人失望，以至于它让人们清楚地看到，整个AI行业在多大程度上是依赖于炒作。

听听奥特曼在GPT-5发布前是怎么说的吧，他将其与前代产品GPT-4o做了个比较：“和GPT-4o聊天，可能就像在跟一个大学生说话，”他说。“但现在有了GPT-5，就好像在跟一位专家交谈——一位在你需要的任何领域里，随叫随到的、真正的博士级专家……无论你的目标是什么。”

嗯，好像没那么神。当一个用户让它生成一张标明所有州的美国地图时，GPT-5 吐出了一张奇幻地图，上面赫然出现了“Tonnessee”、“Mississipo”和“West Wigina”这样的州。另一个用户让它列出美国前12位总统的名字和照片，结果它只给出了9位，还包括“Gearge Washington”、“John Quincy Adama”和“Thomason Jefferson”这些拼写错误的名字。

新版本的前代模型的老用户们都惊呆了，尤其是OpenAI一度决定关闭旧版本，强迫用户使用新版本的做法，更是让他们愤怒。“GPT5太可怕了，”一位用户在Reddit上写道。“回复又短又不充分，说话风格更惹人厌，更没有‘个性’了……而且我们还不能选择用回其他模型。”（在强烈反对下，OpenAI很快让步，重新开放了旧版本。）

科技媒体也同样不买账。科技网站Futurism评价其“有点哑火”，而Ars Technica则称这次发布是“一团糟”。我请OpenAI就公众对GPT-5的负面反应发表评论，但没有收到回复。

然而，所有这一切并不意味着支撑公众对AI期望的“炒作机器”停下来了。恰恰相反，它仍在超速运转。

一个名为“AI未来项目”（AI Futures Project）的组织发布了一份对未来几年AI发展的预测，标题是《AI 2027》。报告宣称：“我们预测，超人AI在未来十年的影响将是巨大的，会超过工业革命。”

这份文件的其余部分描绘了一条通往2027年底的路线图，届时一个AI智能体（AI agent）将“最终理解其自身的认知”。这份报告异想天开到了极点，我甚至怀疑它是不是在故意模仿和讽刺那些过度的AI炒作。我问了报告的创建者们是否如此，但没有得到答复。

GPT-5的平庸表现凸显了一个问题，它打破了AI界最珍视的信条之一，那就是“规模化”（scaling up）——只要给技术投入更多的算力和更多的数据，就能离通用人工智能（artificial general intelligence, AGI）的圣杯越来越近。

正是这个信条，支撑着AI行业在数据中心和高性能芯片上的巨额开销。据摩根士丹利估计，仅到2028年，对更多数据和数据处理能力的需求就将需要约3万亿美元的资本。这个数字将超过全球信贷和衍生品证券市场的承载能力。但如果AI无法通过规模化实现突破，那么这些钱中的大部分（如果不是全部的话）都将付诸东流。

正如本德和汉娜在她们的书中指出的，AI的鼓吹者们之所以能让投资者和追随者们着迷，是利用了公众对“智能”（intelligence）这个词的模糊理解。AI机器人看起来很智能，因为它们已经能够连贯地使用语言。但这和认知（cognition）是两码事。

“所以我们会在文字背后想象出一个心智，”汉娜说，“并将其与意识或智能联系起来。但通用智能这个概念，其实并没有被很好地定义。”

事实上，早在上世纪60年代，这种现象就被约瑟夫·魏泽鲍姆（Joseph Weizenbaum）注意到了。他是开创性的聊天机器人（chatbot）ELIZA的设计者。ELIZA模仿心理治疗师的回答非常逼真，以至于即便是知道自己在和机器对话的测试者，也认为它表现出了情感和同理心。

“我当时没有意识到的是，”魏泽鲍姆在1976年写道，“与一个相对简单的计算机程序进行极短时间的接触，就能在非常正常的人身上诱发出强大的妄想性思维。” 魏泽鲍姆警告说，这种“对计算机鲁莽的拟人化”（anthropomorphization）——也就是把它当作一个会思考的伙伴——产生了一种“对智能的简单化看法”。

今天的AI鼓吹者们恰恰利用了这种倾向。他们把AI机器人经常犯的错误和编造的内容称为“幻觉”（hallucinations），这个词暗示机器人有感知能力，只是偶尔出了点小差错。但正如本德和汉娜所写，“机器人根本没有感知能力，暗示它们有，是又一种毫无帮助的拟人化。”

大众或许终于开始普遍意识到AI承诺的落空。那些预测AI将导致创意和STEM领域（科学、技术、工程和数学）大规模失业的言论，可能会让人们觉得，整个事情从一开始就是一场科技行业的骗局。

预测AI将带来工人生产力大幅提升的说法也并未实现。在许多领域，生产力反而下降了，部分原因是为了防止AI的错误或编造的内容进入关键应用中，企业不得不派员工去反复核对AI的输出——比如，法律文书中包含了不存在的判例，或者医疗处方中存在危及生命的错误等等。

一些经济学家也开始给那些对经济增长的预测泼冷水。例如，麻省理工学院经济学家达龙·阿西莫格鲁（Daron Acemoglu）去年预测，在未来10年内，AI只会为美国生产力带来约0.5%的增长，为国内生产总值带来约1%的增长，这与AI阵营的预测相比，只是个零头。

本德和汉娜的书的价值，以及GPT-5的教训在于，它们提醒我们，“人工智能”不是一个科学术语，也不是一个工程术语，而是一个营销术语。所有关于AI最终将统治世界的喋喋不休，都是如此。

“围绕意识和感知能力的说法，是一种向你推销AI的策略，”本德和汉娜写道。同样，那些关于在AI领域可以赚到数十亿、甚至数万亿美元的言论也是如此。和任何技术一样，利润将流向一小撮人，而我们其他人则要付出代价……除非我们能更清楚地认识到AI是什么，以及更重要的，它不是什么。